{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1OqeglTvs_X"
      },
      "source": [
        "# **Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSBzw95nuj-4",
        "outputId": "2f6a84e6-121f-4899-95a8-d74508fb6774"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "sent1 = \"The saddest aspect of life right now is that science gathers knowledge faster than society gathers wisdom.\"\n",
        "sent2 = \"Life is pleasant. Death is peaceful. It's the transition that's troublesome.\" \n",
        "tokens1 = word_tokenize(sent1)\n",
        "tokens2 = sent_tokenize(sent2)\n",
        "print(tokens1)\n",
        "print(tokens2)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "['The', 'saddest', 'aspect', 'of', 'life', 'right', 'now', 'is', 'that', 'science', 'gathers', 'knowledge', 'faster', 'than', 'society', 'gathers', 'wisdom', '.']\n",
            "['Life is pleasant.', 'Death is peaceful.', \"It's the transition that's troublesome.\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zM5IKFV4qHW8"
      },
      "source": [
        "# **N-GRAMS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcwEbaVL0vZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9df8bfea-5552-4dfe-d7e9-203761367f92"
      },
      "source": [
        "unigram = list(nltk.ngrams(tokens1, 1))\n",
        "bigram = list(nltk.ngrams(tokens1, 2))\n",
        "print(unigram[:5])\n",
        "print(bigram[:5])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('The',), ('saddest',), ('aspect',), ('of',), ('life',)]\n",
            "[('The', 'saddest'), ('saddest', 'aspect'), ('aspect', 'of'), ('of', 'life'), ('life', 'right')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izJt_70cqM-I",
        "outputId": "c003dcca-3012-444e-e1f7-d88b5951c2eb"
      },
      "source": [
        "from nltk import FreqDist\n",
        "\n",
        "print('Most common unigrams: ', FreqDist(unigram).most_common(5))\n",
        "print('Most common bigrams: ', FreqDist(bigram).most_common(5))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most common unigrams:  [(('gathers',), 2), (('The',), 1), (('saddest',), 1), (('aspect',), 1), (('of',), 1)]\n",
            "Most common bigrams:  [(('The', 'saddest'), 1), (('saddest', 'aspect'), 1), (('aspect', 'of'), 1), (('of', 'life'), 1), (('life', 'right'), 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aSBV2rArvcD"
      },
      "source": [
        "# **Stemming**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjCFs_HyrUea",
        "outputId": "8416c500-cd1a-4115-f3d6-0b036428a555"
      },
      "source": [
        "from nltk.stem import PorterStemmer, SnowballStemmer\n",
        "words = [\"fight\", \"fighting\", \"fighter\", \"cows\", \"created\"]\n",
        "words_ru = ['корова', 'мальчики', 'мужчины', 'столом', 'убежала']\n",
        "\n",
        "ps = PorterStemmer()\n",
        "print(list(map(ps.stem, words)))\n",
        "\n",
        "ss = SnowballStemmer(language='russian')\n",
        "print(list(map(ss.stem, words_ru)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['fight', 'fight', 'fighter', 'cow', 'creat']\n",
            "['коров', 'мальчик', 'мужчин', 'стол', 'убежа']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLA8BJTwtihq"
      },
      "source": [
        "# **Lemmatization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dc9KY-Vqu5y",
        "outputId": "ee4e2721-4108-491b-bcc6-6f5989657560"
      },
      "source": [
        "import spacy\n",
        "\n",
        "raw = \"\"\"DENNIS: Listen, strange women lying in ponds distributing swords\n",
        "is no basis for a system of government.  Supreme executive power derives from\n",
        "a mandate from the masses, not from some farcical aquatic ceremony.\"\"\"\n",
        "\n",
        "nlp = spacy.load('en')\n",
        "doc = nlp(raw)\n",
        "print(' '.join([token.lemma_ for token in doc]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "denni : listen , strange woman lie in pond distribute sword \n",
            " be no basis for a system of government .   Supreme executive power derive from \n",
            " a mandate from the masse , not from some farcical aquatic ceremony .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI9cAQgitmP1",
        "outputId": "2826812f-66fe-4bd9-b177-0defb70e5fb8"
      },
      "source": [
        "[(token.lemma_, token.pos_) for token in doc[:7]]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('denni', 'NOUN'),\n",
              " (':', 'PUNCT'),\n",
              " ('listen', 'VERB'),\n",
              " (',', 'PUNCT'),\n",
              " ('strange', 'ADJ'),\n",
              " ('woman', 'NOUN'),\n",
              " ('lie', 'VERB')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPYVxgkgv_kv",
        "outputId": "7c20f41f-95f2-4ab0-d2df-ec236696e67e"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIHANbAYwB2W",
        "outputId": "1fe50028-c98a-4838-a30e-dc6b2c36da28"
      },
      "source": [
        "ent1 = \"The saddest aspect of life right now is that science gathers knowledge faster than society gathers wisdom.\"\n",
        "\n",
        "sentences = nltk.sent_tokenize(sent1)   \n",
        "for sent in sentences:\n",
        "    print(nltk.pos_tag(sent.split()))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('The', 'DT'), ('saddest', 'JJS'), ('aspect', 'NN'), ('of', 'IN'), ('life', 'NN'), ('right', 'NN'), ('now', 'RB'), ('is', 'VBZ'), ('that', 'IN'), ('science', 'NN'), ('gathers', 'NNS'), ('knowledge', 'VBP'), ('faster', 'JJR'), ('than', 'IN'), ('society', 'NN'), ('gathers', 'NNS'), ('wisdom.', 'VBP')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLorIu_pwD1q",
        "outputId": "e91417fa-4eba-460d-e518-196f8b6103e9"
      },
      "source": [
        "nltk.download('universal_tagset')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuvcFvnpxoSq",
        "outputId": "e5679081-e852-4fe7-de3d-4e4a1393516c"
      },
      "source": [
        "word_tag = nltk.pos_tag(sent.split())\n",
        "new_word_tag = [(word, nltk.map_tag('en-ptb', 'universal', tag)) for word, tag in word_tag]\n",
        "print(new_word_tag)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('The', 'DET'), ('saddest', 'ADJ'), ('aspect', 'NOUN'), ('of', 'ADP'), ('life', 'NOUN'), ('right', 'NOUN'), ('now', 'ADV'), ('is', 'VERB'), ('that', 'ADP'), ('science', 'NOUN'), ('gathers', 'NOUN'), ('knowledge', 'VERB'), ('faster', 'ADJ'), ('than', 'ADP'), ('society', 'NOUN'), ('gathers', 'NOUN'), ('wisdom.', 'VERB')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTUCdzMgylRa"
      },
      "source": [
        "# **Named Entity Recognition**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzO9rUNgx2dP",
        "outputId": "32167590-02ff-4b7a-c49f-4d28a95d82c0"
      },
      "source": [
        "doc = nlp('Apple is looking at buying U.K. startup for $1 billion')\n",
        "\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple 0 5 ORG\n",
            "U.K. 27 31 GPE\n",
            "$1 billion 44 54 MONEY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rnd6ezHwnwcP"
      },
      "source": [
        "# **RegExp**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-Fj9okHn1G0",
        "outputId": "201ce8df-acb9-4549-c499-47492b74746a"
      },
      "source": [
        "import re\n",
        "\n",
        "word = 'supercalifragilisticexpialidocious'\n",
        "re.findall('[aeiou]|super', word)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['super', 'a', 'i', 'a', 'i', 'i', 'i', 'e', 'i', 'a', 'i', 'o', 'i', 'o', 'u']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIWypotOo2SM",
        "outputId": "faccd466-30f8-4698-9fd3-e9486640d7c2"
      },
      "source": [
        "re.findall('\\d{1,2}', 'There is some numbers: 49 and 432')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['49', '43', '2']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NJ93saAXo44s",
        "outputId": "89094655-c8d0-4f62-9503-b79941720fdd"
      },
      "source": [
        "re.sub('[,\\.?!]','','How, to? split. text!')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'How to split text'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cBoHLPbo6cu",
        "outputId": "09231891-bc0d-47a2-9695-b41115ea367d"
      },
      "source": [
        "re.sub('[^A-z]',' ','I 123 can 45 play 67 football').split()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I', 'can', 'play', 'football']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJUcebLkpou_"
      },
      "source": [
        "# **Byte Pair Encoding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqDy1cXNq0IA"
      },
      "source": [
        "<img src=\"https://alexanderdyakonov.files.wordpress.com/2019/11/bpe.jpg\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0Esqo-sprU9",
        "outputId": "1751a139-4a14-4cda-eb14-16b3d83df7f2"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "newsgroups_train = fetch_20newsgroups(subset='train')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqiOOzBepuhc",
        "outputId": "ad4f2866-acdf-4959-9b6d-3b09e5e8e110"
      },
      "source": [
        "list(newsgroups_train.target_names)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism',\n",
              " 'comp.graphics',\n",
              " 'comp.os.ms-windows.misc',\n",
              " 'comp.sys.ibm.pc.hardware',\n",
              " 'comp.sys.mac.hardware',\n",
              " 'comp.windows.x',\n",
              " 'misc.forsale',\n",
              " 'rec.autos',\n",
              " 'rec.motorcycles',\n",
              " 'rec.sport.baseball',\n",
              " 'rec.sport.hockey',\n",
              " 'sci.crypt',\n",
              " 'sci.electronics',\n",
              " 'sci.med',\n",
              " 'sci.space',\n",
              " 'soc.religion.christian',\n",
              " 'talk.politics.guns',\n",
              " 'talk.politics.mideast',\n",
              " 'talk.politics.misc',\n",
              " 'talk.religion.misc']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "choq8sqHp0i0"
      },
      "source": [
        "cats = ['alt.atheism', 'sci.space']\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9RwMekep_6u",
        "outputId": "81209735-7799-4c06-db97-18b724892256"
      },
      "source": [
        "list(newsgroups_train.target_names)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alt.atheism', 'sci.space']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOgPM_l2qDXn",
        "outputId": "d20e7afb-0a2d-4a66-eec6-6e6eb6a567d5"
      },
      "source": [
        "print(newsgroups_train.data[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: bil@okcforum.osrhe.edu (Bill Conner)\n",
            "Subject: Re: Not the Omni!\n",
            "Nntp-Posting-Host: okcforum.osrhe.edu\n",
            "Organization: Okcforum Unix Users Group\n",
            "X-Newsreader: TIN [version 1.1 PL6]\n",
            "Lines: 18\n",
            "\n",
            "Charley Wingate (mangoe@cs.umd.edu) wrote:\n",
            ": \n",
            ": >> Please enlighten me.  How is omnipotence contradictory?\n",
            ": \n",
            ": >By definition, all that can occur in the universe is governed by the rules\n",
            ": >of nature. Thus god cannot break them. Anything that god does must be allowed\n",
            ": >in the rules somewhere. Therefore, omnipotence CANNOT exist! It contradicts\n",
            ": >the rules of nature.\n",
            ": \n",
            ": Obviously, an omnipotent god can change the rules.\n",
            "\n",
            "When you say, \"By definition\", what exactly is being defined;\n",
            "certainly not omnipotence. You seem to be saying that the \"rules of\n",
            "nature\" are pre-existant somehow, that they not only define nature but\n",
            "actually cause it. If that's what you mean I'd like to hear your\n",
            "further thoughts on the question.\n",
            "\n",
            "Bill\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBnFZhrnqGny",
        "outputId": "9239487a-72be-42b6-c096-a2b8430534a9"
      },
      "source": [
        "newsgroups_train.target[:10]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 1, 1, 0, 1, 1, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIGhN5Jdqrxu",
        "outputId": "d9ebd668-861f-4ae6-9bf4-2b8d24033a0d"
      },
      "source": [
        "!pip install youtokentome"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting youtokentome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/65/4a86cf99da3f680497ae132329025b291e2fda22327e8da6a9476e51acb1/youtokentome-1.0.6-cp36-cp36m-manylinux2010_x86_64.whl (1.7MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7MB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from youtokentome) (7.1.2)\n",
            "Installing collected packages: youtokentome\n",
            "Successfully installed youtokentome-1.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roS8A0I4zZTe",
        "outputId": "93500394-dc93-442e-8c15-575d22de072d"
      },
      "source": [
        "import youtokentome as yttm\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "stopWords = set(stopwords.words('english'))\n",
        "nltk.download('wordnet')\n",
        "wnl = nltk.WordNetLemmatizer()\n",
        "\n",
        "def preproc1(text):\n",
        "    return ' '.join([wnl.lemmatize(word) for word in word_tokenize(text.lower()) if word not in stopWords])\n",
        "\n",
        "def train_bpe(records, preproc, model_path, model_type=\"bpe\", vocab_size=10000, lower=True):\n",
        "    temp_file_name = \"temp.txt\"\n",
        "    with open(temp_file_name, \"w\") as temp:\n",
        "        for text in records:\n",
        "            temp.write(preproc(text) + \"\\n\")\n",
        "\n",
        "    yttm.BPE.train(data=temp_file_name, vocab_size=vocab_size, model=model_path)\n",
        "\n",
        "train_bpe(records=newsgroups_train.data, preproc=preproc1, model_path=\"BPE_model.bin\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2mlrdMKzo80",
        "outputId": "b7eb7251-7ac2-4b79-990b-903df74031be"
      },
      "source": [
        "bpe_processor = yttm.BPE('BPE_model.bin')\n",
        "bpe_processor.vocab()[::1000]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<PAD>',\n",
              " '▁gra',\n",
              " '▁observatory',\n",
              " '▁roll',\n",
              " '▁575-3539',\n",
              " '▁originator',\n",
              " '▁fred.mccall',\n",
              " 'graph',\n",
              " '▁psilink-dos',\n",
              " '▁carrying']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aW1pmX6Y06ID"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}